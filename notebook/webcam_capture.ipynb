{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "try:\n",
    "    from greenlet import getcurrent as get_ident\n",
    "except ImportError:\n",
    "    try:\n",
    "        from thread import get_ident\n",
    "    except ImportError:\n",
    "        from _thread import get_ident\n",
    "\n",
    "\n",
    "class CameraEvent(object):\n",
    "    \"\"\"An Event-like class that signals all active clients when a new frame is\n",
    "    available.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = {}\n",
    "\n",
    "    def wait(self):\n",
    "        \"\"\"Invoked from each client's thread to wait for the next frame.\"\"\"\n",
    "        ident = get_ident()\n",
    "        if ident not in self.events:\n",
    "            # this is a new client\n",
    "            # add an entry for it in the self.events dict\n",
    "            # each entry has two elements, a threading.Event() and a timestamp\n",
    "            self.events[ident] = [threading.Event(), time.time()]\n",
    "        return self.events[ident][0].wait()\n",
    "\n",
    "    def set(self):\n",
    "        \"\"\"Invoked by the camera thread when a new frame is available.\"\"\"\n",
    "        now = time.time()\n",
    "        remove = None\n",
    "        for ident, event in self.events.items():\n",
    "            if not event[0].isSet():\n",
    "                # if this client's event is not set, then set it\n",
    "                # also update the last set timestamp to now\n",
    "                event[0].set()\n",
    "                event[1] = now\n",
    "            else:\n",
    "                # if the client's event is already set, it means the client\n",
    "                # did not process a previous frame\n",
    "                # if the event stays set for more than 5 seconds, then assume\n",
    "                # the client is gone and remove it\n",
    "                if now - event[1] > 5:\n",
    "                    remove = ident\n",
    "        if remove:\n",
    "            del self.events[remove]\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Invoked from each client's thread after a frame was processed.\"\"\"\n",
    "        self.events[get_ident()][0].clear()\n",
    "\n",
    "\n",
    "class BaseCamera(object):\n",
    "    thread = None  # background thread that reads frames from camera\n",
    "    frame = None  # current frame is stored here by background thread\n",
    "    last_access = 0  # time of last client access to the camera\n",
    "    event = CameraEvent()\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Start the background camera thread if it isn't running yet.\"\"\"\n",
    "        if BaseCamera.thread is None:\n",
    "            BaseCamera.last_access = time.time()\n",
    "\n",
    "            # start background frame thread\n",
    "            BaseCamera.thread = threading.Thread(target=self._thread)\n",
    "            BaseCamera.thread.start()\n",
    "\n",
    "            # wait until frames are available\n",
    "            while self.get_frame() is None:\n",
    "                time.sleep(0)\n",
    "\n",
    "    def get_frame(self):\n",
    "        \"\"\"Return the current camera frame.\"\"\"\n",
    "        BaseCamera.last_access = time.time()\n",
    "\n",
    "        # wait for a signal from the camera thread\n",
    "        BaseCamera.event.wait()\n",
    "        BaseCamera.event.clear()\n",
    "\n",
    "        return BaseCamera.frame\n",
    "\n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        \"\"\"\"Generator that returns frames from the camera.\"\"\"\n",
    "        raise RuntimeError('Must be implemented by subclasses.')\n",
    "\n",
    "    @classmethod\n",
    "    def _thread(cls):\n",
    "        \"\"\"Camera background thread.\"\"\"\n",
    "        print('Starting camera thread.')\n",
    "        frames_iterator = cls.frames()\n",
    "        for frame in frames_iterator:\n",
    "            BaseCamera.frame = frame\n",
    "            BaseCamera.event.set()  # send signal to clients\n",
    "            time.sleep(0)\n",
    "\n",
    "            # if there hasn't been any clients asking for frames in\n",
    "            # the last 10 seconds then stop the thread\n",
    "            if time.time() - BaseCamera.last_access > 10:\n",
    "                frames_iterator.close()\n",
    "                print('Stopping camera thread due to inactivity.')\n",
    "                break\n",
    "        BaseCamera.thread = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera_compare(BaseCamera):\n",
    "    video_source = 0\n",
    "    last_encoding = []\n",
    "    encodings_core = {}\n",
    "    encodings_few = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def set_video_source(source):\n",
    "        Camera_compare.video_source = source\n",
    "\n",
    "    def add_to_core(encoding):\n",
    "        print(\"Encoding found\")\n",
    "        if bool(Camera_compare.encodings_core):\n",
    "            likehood_counter = 0\n",
    "            merge_dict = {}\n",
    "            for key, value in Camera_compare.encodings_core.items():\n",
    "                if any(face_recognition.compare_faces(value, encoding, tolerance = 0.2)):\n",
    "                    print(\"Found likeness in core, appending\")\n",
    "                    Camera_compare.encodings_core[key].append(encoding)\n",
    "                    if likehood_counter > 0:\n",
    "                        merge_dict[merge_num_0]=key\n",
    "                    else:\n",
    "                        merge_num_0 = key\n",
    "                    likehood_counter += 1\n",
    "            if likehood_counter == 0:\n",
    "                print(\"No likeness found, creating new node\")\n",
    "                Camera_compare.encodings_core[len(Camera_compare.encodings_core)]=[encoding]       \n",
    "            if bool(merge_dict):\n",
    "                print(\"Similar nodes found, merging dict is: %s\"%merge_dict)\n",
    "                for key, value in merge_dict.items():\n",
    "                    Camera_compare.encodings_core[key].extend(Camera_compare.encodings_core[value].pop())\n",
    "                        \n",
    "        else:\n",
    "            print(\"core is empty, adding first node\")\n",
    "            Camera_compare.encodings_core[len(Camera_compare.encodings_core)]=[encoding]\n",
    "                \n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        camera = cv2.VideoCapture(Camera_compare.video_source)\n",
    "        if not camera.isOpened():\n",
    "            raise RuntimeError('Could not start camera.')\n",
    "\n",
    "\n",
    "        while True:\n",
    "            # read current frame\n",
    "            _, frame = camera.read()\n",
    "\n",
    "            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "            rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "            # Find all the faces and face enqcodings in the frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            #face_landmarks_list = face_recognition.face_landmarks(rgb_frame)\n",
    "            \n",
    "            # Loop through each face in this frame of video\n",
    "            face_iter = 0\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                Camera_compare.add_to_core(face_encoding)\n",
    "                # See if the face is a match for the known face(s)\n",
    "                #if len(Camera_compare.last_encoding)!=0:\n",
    "                #    compare_result = face_recognition.face_distance([Camera_compare.last_encoding], face_encoding)\n",
    "                #else:\n",
    "                #    compare_result = 0\n",
    "                #if face_iter == 0:\n",
    "                #    Camera_compare.last_encoding = face_encoding\n",
    "           \n",
    "                \n",
    "        \n",
    "                face_iter += 1\n",
    "\n",
    "                #print(\"Difference %s\"%compare_result)\n",
    "                \n",
    "                # Draw a box around the face\n",
    "                #cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                #cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                #font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                #cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "                \n",
    "            #for face_landmarks in face_landmarks_list:\n",
    "            #    pil_image = Image.fromarray(frame)\n",
    "            #    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "            #    # Make the eyebrows into a nightmare\n",
    "            #    print(face_landmarks['left_eyebrow'])\n",
    "            #    d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "            #    d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "            #    frame = numpy.array(pil_image.getdata(),\n",
    "            #        numpy.uint8).reshape(pil_image.size[1], pil_image.size[0], 3)\n",
    "            # encode as a jpeg image and return it\n",
    "            #yield cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "            yield frame\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Camera_compare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cff36734ebd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCamera_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCamera_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Camera_compare' is not defined"
     ]
    }
   ],
   "source": [
    "Camera_compare.encodings_core\n",
    "Camera_compare.encodings_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting camera thread.\n",
      "Encoding found\n",
      "core is empty, adding first node\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "Found likeness in core, appending\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "Found likeness in core, appending\n",
      "Encoding found\n",
      "Found likeness in core, appending\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "No likeness found, creating new node\n",
      "Encoding found\n",
      "Found likeness in core, appending\n",
      "Stopping camera thread due to inactivity.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(10):\n",
    "    frame = Camera_compare().get_frame()\n",
    "    #cv2.imwrite('../data/out/%s.png'%i,frame)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
